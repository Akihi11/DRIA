"""
FastAPI main application module - Python 3.12 compatible
"""
from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from fastapi.openapi.utils import get_openapi
import logging
from datetime import datetime
import sys
import os
from pathlib import Path
from contextlib import asynccontextmanager

# ç¡®ä¿å¯ä»¥ä»é¡¹ç›®æ ¹ç›®å½•å¯¼å…¥
project_root = Path(__file__).parent.parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from config import settings
from models.api_models import ErrorResponse
from api.routes import (
    dialogue,
    health,
    config,
    upload,
    analysis,
    config_dialogue,
    steady_state,
    status_evaluation,
    functional,
    report_config,
    combined_report,
)
from backend.services.db import init_schema

# Configure logging
logging.basicConfig(level=getattr(logging, settings.LOG_LEVEL))
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Application lifespan context manager"""
    import asyncio
    
    # å¯åŠ¨æ—¶æ‰§è¡Œçš„ä»£ç 
    logger.info("AI Chat API starting up (Python 3.12 compatible)...")
    logger.info(f"Python version: {sys.version}")
    logger.info(f"Current working directory: {os.getcwd()}")
    
    logger.info(f"Debug mode: {settings.DEBUG}")
    
    # æ˜¾ç¤ºé…ç½®çŠ¶æ€
    available_providers = settings.get_available_providers()
    logger.info(f"Default LLM provider: {settings.DEFAULT_LLM_PROVIDER}")
    logger.info(f"Available providers: {available_providers}")
    
    if not available_providers:
        logger.warning("âš ï¸  æ²¡æœ‰å¯ç”¨çš„LLMæä¾›å•†ï¼è¯·æ£€æŸ¥.envé…ç½®æ–‡ä»¶")
    elif not settings.is_provider_available(settings.DEFAULT_LLM_PROVIDER):
        logger.warning(f"âš ï¸  é»˜è®¤æä¾›å•† '{settings.DEFAULT_LLM_PROVIDER}' ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨: {available_providers[0]}")
    else:
        logger.info(f"âœ… é»˜è®¤æä¾›å•† '{settings.DEFAULT_LLM_PROVIDER}' å·²æ­£ç¡®é…ç½®")
    
    try:
        init_schema()
        logger.info("âœ… æ•°æ®åº“è¡¨ç»“æ„æ£€æŸ¥å®Œæˆ")
    except Exception as db_err:
        logger.warning(f"âš ï¸ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥ï¼Œç›¸å…³åŠŸèƒ½å°†ä¸å¯ç”¨: {db_err}")
    
    logger.info("AI Chat API ready for pure dialogue conversations")
    
    yield
    
    # å…³é—­æ—¶æ‰§è¡Œçš„ä»£ç 
    try:
        logger.info("AI Chat API shutting down...")
    except asyncio.CancelledError:
        # åœ¨å…³é—­è¿‡ç¨‹ä¸­ï¼ŒCancelledError æ˜¯æ­£å¸¸çš„ï¼Œä¸éœ€è¦è®°å½•ä¸ºé”™è¯¯
        logger.debug("Server shutdown cancelled (normal during shutdown)")
        raise  # é‡æ–°æŠ›å‡ºä»¥æ­£ç¡®ä¼ æ’­å–æ¶ˆä¿¡å·


# Create FastAPI application
app = FastAPI(
    title="AI Chat API",
    description="çº¯å¯¹è¯AIåŠ©æ‰‹ API - ç”¨æˆ·ä¸å¤§æ¨¡å‹ç›´æ¥å¯¹è¯",
    version="1.0.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc",
    openapi_url="/api/openapi.json",
    lifespan=lifespan
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure appropriately for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Include routers
app.include_router(health.router, prefix="/api", tags=["Health"])
app.include_router(dialogue.router, prefix="/api", tags=["Dialogue"])
app.include_router(config.router, prefix="/api/config", tags=["Config"])
app.include_router(config_dialogue.router, prefix="/api/config-dialogue", tags=["Config Dialogue"])
app.include_router(upload.router, prefix="/api", tags=["Upload"])
app.include_router(analysis.router, prefix="/api", tags=["Analysis"])
app.include_router(steady_state.router, prefix="/api", tags=["Steady State Reports"])
app.include_router(status_evaluation.router, prefix="/api", tags=["Status Evaluation Reports"])
app.include_router(functional.router, prefix="/api", tags=["Functional Reports"])
app.include_router(report_config.router, prefix="/api", tags=["Report Config"])
app.include_router(combined_report.router, prefix="/api", tags=["Combined Reports"])


@app.exception_handler(Exception)
async def global_exception_handler(request: Request, exc: Exception):
    """Global exception handler"""
    logger.error(f"Unhandled exception: {exc}", exc_info=True)
    
    error_response = ErrorResponse(
        error="InternalServerError",
        message="An internal server error occurred",
        timestamp=datetime.now().isoformat()
    )
    
    return JSONResponse(
        status_code=500,
        content=error_response.model_dump()
    )


def custom_openapi():
    """Custom OpenAPI schema generation"""
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title="AI Chat API",
        version="1.0.0",
        description=f"""
        ## AIçº¯å¯¹è¯åŠ©æ‰‹API
        
        **Pythonç‰ˆæœ¬**: {sys.version}
        **è¿è¡Œç¯å¢ƒ**: Python 3.12 å…¼å®¹æ¨¡å¼
        
        æœ¬APIæä¾›ä»¥ä¸‹æ ¸å¿ƒåŠŸèƒ½ï¼š
        
        ### ğŸ’¬ çº¯å¯¹è¯åŠŸèƒ½
        - ç”¨æˆ·ä¸å¤§æ¨¡å‹ç›´æ¥å¯¹è¯
        - æ™ºèƒ½AIåŠ©æ‰‹å“åº”
        - å¤šè½®å¯¹è¯çŠ¶æ€ç®¡ç†
        - ä¼šè¯ç®¡ç†
        
        ### ç³»ç»Ÿç›‘æ§
        - å¥åº·æ£€æŸ¥
        - æœåŠ¡çŠ¶æ€ç›‘æ§
        
        ### ğŸ”§ Python 3.12 é€‚é…è¯´æ˜
        - ä½¿ç”¨å…¼å®¹çš„ä¾èµ–åŒ…ç‰ˆæœ¬
        - ä¼˜åŒ–äº†æ•°æ®å¤„ç†é€»è¾‘
        - æ”¯æŒæœ€æ–°çš„Pythonç‰¹æ€§
        """,
        routes=app.routes,
    )
    
    # Add custom info
    openapi_schema["info"]["contact"] = {
        "name": "DRIA Development Team",
        "email": "support@dria.com"
    }
    
    openapi_schema["info"]["x-python-version"] = sys.version
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema


app.openapi = custom_openapi




if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "api.main:app",
        host=settings.API_HOST,
        port=settings.API_PORT,
        reload=settings.DEBUG,
        log_level=settings.LOG_LEVEL.lower()
    )