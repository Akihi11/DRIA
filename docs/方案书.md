实验报表生成方案设计

1 引言

本项目旨在为DHDAS软件开发一个基于对话式人工智能的报表生成模块。当前DHDAS软件的报表功能依赖于针对每个客户的定制化开发，流程僵化且效率低下。本方案要解决的核心问题是：用一套灵活的、可通过自然语言交互配置的AI系统，替代原有“写死”逻辑的手动配置流程，实现报表的自动化生成。

最终目标是交付一个功能可用的AI报表生成模块原型，能够通过对话理解用户需求，自动处理DHDAS导出的信号数据，并生成符合规范的报表。该模块的核心价值在于大幅提升报表生成效率，并为未来扩展至更多测试场景提供灵活的AI框架。

对话与流程管理模块：负责管理与用户的完整对话流程，并调度其他模块协同工作。

数据接口与预分析模块：负责处理所有与用户原始数据文件的交互。

规则与知识管理模块：存储所有关于如何生成报表的知识和规则。

分析计算与报表生成模块：执行所有繁重的、精确的数值计算，并生成最终的报表。 

 

2 总体设计

2.1 设计思想

本方案采用以大型语言模型（LLM）为核心的智能代理（Agent）系统作为顶层设计思想。整个系统通过将用户的自然语言需求拆解为一系列明确的步骤（数据解析、特征计算、报表填充），并协同各个功能组件自主完成任务，最终交付符合用户需求的精准报表。

 

2.2 系统架构

系统采用前后端分离的架构。前端负责提供用户交互界面（初期可以是命令行界面），后端通过API接口接收前端请求。AI代理后台服务是核心，它利用AI编排框架管理业务逻辑，调用大型语言模型进行意图理解和决策，并从知识库中检索信息以辅助分析，最终驱动整个报表生成流程。
 ![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271656663.png)

   

2.2.1 系统交互与数据流设计

**核心架构**

系统采用解耦的双服务部署模式，在本地服务器环境中并行运行两个核心服务：

- AI应用服务器: 基于FastAPI+ LangGraph构建的后端程序，承载系统的核心业务逻辑。
- 大模型推理服务器:     专门用于加载并运行大语言模型（如Qwen），并对外提供标准化的文本生成API接口。

所有服务将通过Docker容器化技术进行封装与部署，以确保开发、测试及生产环境的高度一致性。

**通信协议**

AI应用服务器与大模型推理服务器之间的通信，将通过HTTP API调用的方式实现。此设计遵循现代微服务架构的最佳实践，保障了模块间的松耦合关系，便于独立开发、测试与未来升级。AI应用服务器作为客户端，将向LLM服务器的API端点发起HTTP POST请求以获取模型推理结果。

**数据格式**

所有通过API接口传输的数据，均采用JSON格式进行封装。请求体（Request Body）将包含指令（Prompt）、对话历史及其他推理参数；响应体（Response Body）将包含由大模型生成的文本结果。这种标准化的数据格式确保了不同服务间的互操作性与数据解析的便捷性。

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271656493.png)

 

2.3 技术选型

| **组件类别**              | **技术选型**              | **选用理由**                                                 |
| ------------------------- | ------------------------- | ------------------------------------------------------------ |
| **前端框架**              | Vue.js                    | 组件化开发、生态系统成熟、社区活跃                           |
| **后端框架**              | FastAPI (Python)          | 具备极高的性能，原生支持异步IO，这对于处理LLM的长时间等待操作很重要。 |
| **数据处理核心**          | Pandas + NumPy            | Pandas是Python数据处理和分析的基石，NumPy为所有底层数值计算提供高性能支持，是科学计算的核心。 |
| **AI****编排框架**        | LangChain & LangGraph     | **核心调度中心**。用于构建我们设计的、包含工具调用和循环逻辑的复杂Agent流程。LangGraph尤其适合需要多步、可回溯的对话状态管理。 |
| **大语言模型**            | Qwen3-8B                  | 国产开源模型，具备强大的指令遵循和代码生成能力。             |
| **规则库****/****知识库** | JSON / YAML 文件->MongoDB | 初期敏捷开发，后期具备良好的扩展性。                         |
| **部署与编排**            | Docker                    | 采用容器化技术确保开发、测试和生产环境的一致性。             |

 

3 核心功能实现方案

本方案的核心在于将四个功能模块——对话与流程管理、数据接口与预分析、规则与知识管理、分析计算与报表生成，无缝集成为一个由AI智能体驱动的自动化工作流。各模块通过标准化的数据接口（API）进行通信，实现从用户需求到最终报表的端到端处理。

整个流程的整合逻辑如下：

① 任务启动与数据认知：流程由用户向对话与流程管理模块上传数据文件并发起初步指令（如“分析这份报告”）开始。该模块接收到指令后，立即调用数据接口与预分析模块。

② 数据预分析与特征返回：数据接口与预分析模块负责读取并清洗原始文件，提取出关键的元数据（如包含的通道名称、数值范围等），并将这些结构化的信息（通常为JSON格式）返回给对话与流程管理模块。

③ 规则匹配与对话策略生成：对话与流程管理模块根据用户的初步意图，向规则与知识管理模块查询生成该报表所需的规则和参数模板。结合上一步返回的文件特征，AI大脑现在已经“知己知彼”——既知道用户的目标，也知道用户的数据情况。

④ 智能引导与参数确认：对话与流程管理模块基于现有信息，与用户进行智能化的、引导性的多轮对话，以补全所有必需的分析参数（如各项评估的阈值）。在获取全部参数后，它会向用户进行最终的任务复述和确认。

⑤ 计算执行与报表生成：在用户确认后，对话与流程管理模块将包含文件引用和完整参数的最终指令，发送给分析计算与报表生成模块。该模块作为计算核心，负责执行所有繁重的数值分析，并将最终生成的报表（以Markdown表格或JSON等结构化格式）返回。

⑥ 结果呈现与迭代闭环：对话与流程管理模块接收到最终报表，将其包装成自然语言的回复呈现给用户。同时，它会保持对话状态，等待用户可能提出的修改标准、重新生成或进行更深层次分析的后续指令，形成一个完整的人机协作闭环。

通过这种设计，我们将复杂的报表任务清晰地解耦为四个独立的、功能专一的模块。AI智能体则扮演着总指挥的角色，负责编排和驱动整个数据流（自然语言 -> JSON配置 -> Python数据对象 -> Excel文件或其他格式），确保各个环节顺畅流转，最终高效地完成任务。

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271657437.png)

 ![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271657944.png)

3.1 对话与流程管理

作为系统的“大脑”，管理与用户的完整对话流程，并调度其他模块协同工作。

3.1.1 实现设计

① **会话初始化与上下文建立：**当用户发起第一次对话时，本模块会创建一个唯一的会话（Session）对象。此对象将作为本次任务的“短期记忆”，存储包括文件ID、对话历史、当前状态和已收集的参数等所有上下文信息。初始状态被设置为AWAITING_PRE_ANALYSIS.

② **数据认知与意图识别：**模块检测到AWAITING_PRE_ANALYSIS状态后，会并行执行两个动作：首先，调用**数据接口与预分析模块**以获取文件的基本特征（如包含的通道）；其次，调用大语言模型(LLM)来识别用户的核心意图（如“生成状态评估表”）。

③ **规则匹配与参数收集循环：**在获取文件特征和用户意图后，模块会查询**规则与知识管理模块**以确定该意图需要哪些参数。随后，它进入一个循环状态：比较“需要”的参数和“已有”的参数，找出下一个需要询问的目标，然后调用LLM结合文件特征动态生成一个智能化的引导性问题（例如，根据数据范围推荐一个合理的阈值），并等待用户回复。此循环将持续进行，直到所有必要参数都收集完毕。

④ **任务确认与执行指令下发：**参数收集完毕后，模块会调用LLM生成一段总结性的文本，向用户复述即将执行的完整任务（包括数据源、报表类型和所有参数），并请求最终确认。得到用户肯定后，模块会将所有信息打包成一个结构化的指令（JSON格式），发送给**分析计算与报表生成模块**。

⑤ **结果呈现与迭代准备：**模块接收到后端返回的最终报表结果后，会将其呈现给用户，并可选择性地调用LLM生成一句简短的解读。此时，会话状态更新为TASK_COMPLETE，但所有上下文依然保留，为用户可能提出的修改标准、重新生成或深化提问做好准备，形成交互闭环。

3.1.2 流程

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271658305.png)

 

3.2 数据接口与预分析

系统的“眼睛”，处理所有与用户原始数据文件的交互。

3.2.1 实现设计

① **文件接收与格式校验：**模块通过API接收来自“对话模块”的文件引用。首先，它会校验文件的格式（是否为支持的CSV/Excel等）、大小以及是否存在明显的损坏，确保文件可被处理。

② **数据读取与结构化清洗：**校验通过后，模块使用专业的库（如Pandas）读取文件内容。此阶段的核心是处理各种不规范的数据格式，例如多行表头、不规则的空格、非数值内容等，最终目标是输出一个内部统一的、干净的结构化数据对象（DataFrame）。

③ **特征提取与元数据生成：**在数据清洗的基础上，模块对核心数据列进行快速的统计分析，提取出对“对话模块”有用的元数据，例如：所有通道的名称列表、关键通道（如转速）的最大/最小值、数据的时间跨度等。这些信息最终会被打包成一个JSON对象返回。

3.2.2 流程

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271658378.png)

 

3.3 规则与知识管理

系统的“知识库”，存储所有关于如何生成报表的规则。

3.3.1 实现设计

① **请求接收与规则检索：**模块接收来自“对话模块”的查询请求，请求中包含一个报表类型的唯一标识（如status_evaluation_report）。模块根据此标识在其内部的规则库（JSON文件或数据库）中进行精确查找。

② **规则结构化输出：**找到匹配的规则后，模块将规则内容格式化为一个标准的JSON对象返回。该对象详细描述了生成该报表所需的所有参数（名称、数据类型、默认值等）、依赖的数据通道类型以及应该调用哪个后端计算函数。

③ **模板解析与动态规则生成：**当接收到的请求是一个用户上传的模板文件而非标准报表类型时，此阶段被激活。模块会解析模板的结构（如列标题），并调用LLM进行“反向工程”，尝试推断出生成这份未知报表所需的参数和基本计算逻辑，并将其格式化为一套临时的规则返回。

3.3.2 流程

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271658379.png)

3.4 分析计算与报表生成

系统的“计算核心”，负责执行所有精确的数值分析。

3.4.1 实现设计

① **任务接收与参数校验：**模块通过API接收来自“对话模块”的最终执行指令（包含文件引用和完整参数的JSON对象）。它首先会严格校验指令中的所有参数是否齐全、格式是否正确，确保计算任务可以被执行。

② **数据加载与预处理：**参数校验无误后，模块根据文件引用加载相应的数据。随后，它会根据具体的计算需求，进行数据预处理，例如计算后续分析所需的滚动平均值、差分值等中间数据列。

③ **核心逻辑计算：**此阶段执行具体的、确定性的计算脚本。根据指令中的任务类型（例如run_status_eval），模块会调用对应的分析函数。该函数将严格按照传入的参数和《研发任务书》中定义的逻辑，对预处理后的数据进行扫描、判断和计算。

④ **结果格式化与输出：**核心计算完成后，此阶段负责将原始的计算结果（如Python字典或列表）格式化为最终呈现给用户的样式，最常见的是一个结构化的Markdown表格字符串。格式化后的结果将通过API返回给“对话模块”。

3.4.2 流程

![](https://hakihi.oss-cn-shanghai.aliyuncs.com/img/202509271659725.png)

 

4 详细设计


 